{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import faiss\n",
    "import sqlite3\n",
    "import argparse\n",
    "from os.path import exists\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn.functional as F\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder:\n",
    "    def __init__(self, model_name=None, to_cuda=True, client=None, use_openai=True, attn_implementation=None):\n",
    "        self.use_openai = use_openai\n",
    "        if use_openai:\n",
    "            self.model_name = model_name\n",
    "            if client is None:\n",
    "                self.client = OpenAI()\n",
    "            else:\n",
    "                self.client = client\n",
    "        else: # Load a PyTorch model and tokenizer\n",
    "\n",
    "            # The attention implementation to use in the model (if relevant). Can be any of \n",
    "            # `\"eager\"` (manual implementation of the attention), \n",
    "            # `\"sdpa\"` (using [`F.scaled_dot_product_attention`](https://pytorch.org/docs/master/generated/torch.nn.functional.scaled_dot_product_attention.html)), \n",
    "            # or `\"flash_attention_2\"` (using [Dao-AILab/flash-attention](https://github.com/Dao-AILab/flash-attention)). \n",
    "            # By default, if available, SDPA will be used for torch>=2.1.1. The default is otherwise the manual `\"eager\"` implementation.\n",
    "            self.attn_implementation = attn_implementation\n",
    "            self.model_name = model_name\n",
    "            self.to_cuda = to_cuda\n",
    "\n",
    "            if attn_implementation:\n",
    "                self.model = AutoModel.from_pretrained(model_name, \n",
    "                                    trust_remote_code=True, \n",
    "                                    attn_implementation=\"flash_attention_2\", \n",
    "                                    torch_dtype=torch.float16).to('cuda' if to_cuda else 'cpu')\n",
    "            else:\n",
    "                self.model = AutoModel.from_pretrained(model_name, \n",
    "                                    trust_remote_code=True, \n",
    "\n",
    "                                    torch_dtype=torch.float16).to('cuda' if to_cuda else 'cpu')\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            self.model.eval()\n",
    "\n",
    "    def get_embedding(self, text: str) -> np.ndarray:\n",
    "        if self.use_openai:\n",
    "            query_embedding_response = self.client.embeddings.create(\n",
    "                model=self.model_name,\n",
    "                input=text\n",
    "            )\n",
    "            return np.array(query_embedding_response.data[0].embedding, dtype='f')\n",
    "        else:\n",
    "            return np.array(self.encode([text])[0], dtype='f')\n",
    "\n",
    "            \n",
    "    def weighted_mean_pooling(self, hidden, attention_mask):\n",
    "        attention_mask_ = attention_mask * attention_mask.cumsum(dim=1)\n",
    "        s = torch.sum(hidden * attention_mask_.unsqueeze(-1).float(), dim=1)\n",
    "        d = attention_mask_.sum(dim=1, keepdim=True).float()\n",
    "        reps = s / d\n",
    "        return reps\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def encode(self, input_texts):\n",
    "        batch_dict = self.tokenizer(input_texts, max_length=512, padding=True, truncation=True, return_tensors='pt', return_attention_mask=True).to('cuda' if self.to_cuda else 'cpu')\n",
    "        \n",
    "        outputs = self.model(**batch_dict)\n",
    "        attention_mask = batch_dict[\"attention_mask\"]\n",
    "        hidden = outputs.last_hidden_state\n",
    "\n",
    "        reps = self.weighted_mean_pooling(hidden, attention_mask)   \n",
    "        embeddings = F.normalize(reps, p=2, dim=1).detach().cpu().numpy()\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.01122869, -0.02335457, -0.002179  , ..., -0.01329134,\n",
       "       -0.02295973,  0.01809652], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CPM_embedder = Embedder(model_name=\"openbmb/MiniCPM-Embedding\",\n",
    "                    use_openai=False, \n",
    "                    attn_implementation=\"flash_attention_2\",\n",
    "                    to_cuda=True)\n",
    "\n",
    "CPM_embedder.get_embedding(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01918462, -0.02527903, -0.00171952, ..., -0.02264216,\n",
       "        0.00563363, -0.01059459], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_embedder = Embedder(model_name=\"text-embedding-3-small\",\n",
    "                        use_openai=True)\n",
    "\n",
    "GPT_embedder.get_embedding(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This version of faiss search requires a sqlite3.Connection object AND an IVFPQ index object\n",
    "def faiss_search(\n",
    "    query: str,\n",
    "    con: sqlite3.Connection,\n",
    "    index: faiss.Index,\n",
    "    embedder: Embedder,\n",
    "    top: int = 5\n",
    ") -> tuple[list[str], list[float]]:\n",
    "    \"\"\"Returns a list of strings and relatednesses, sorted from most related to least.\"\"\"\n",
    "    cur = con.cursor()\n",
    "    query_embedding = embedder.get_embedding(query)\n",
    "\n",
    "    # I is a list of list of index\n",
    "    # D is a list of list of error (relatedness)\n",
    "    D, I = index.search(np.array([query_embedding], dtype='f'), top)\n",
    "    # print(I)\n",
    "    # print(D)\n",
    "\n",
    "    related_text = []\n",
    "\n",
    "    #### This doesn't work:\n",
    "    #### row = 1000\n",
    "    #### cur.execute(\"SELECT content FROM reviews WHERE row_number=?\", (row,)).fetchall()\n",
    "    #### But this works:\n",
    "    #### cur.execute(\"SELECT content FROM reviews WHERE row_number=?\", (1000,)).fetchall()\n",
    "\n",
    "    ### probably b/c how python treat one-element tuple w/ variable differently...\n",
    "\n",
    "    ### Current workaround is to first\n",
    "    ### eval(f\"({row},)\") \n",
    "\n",
    "    for row, err in zip(I[0], D[0]):\n",
    "        ## retrieve corresponding row from db\n",
    "        input = eval(f\"({row},)\")\n",
    "        content = cur.execute('SELECT content FROM reviews WHERE row_number=?', input).fetchone()[0]\n",
    "        related_text.append((content, err))\n",
    "\n",
    "    # might not needed\n",
    "    if len(related_text) == 0:\n",
    "        related_text.append((\"No results found.\", -1))\n",
    "\n",
    "    related_text.sort(key=lambda x: x[1], reverse=True)\n",
    "    strings, relatednesses = zip(*related_text)\n",
    "    return strings[:top], relatednesses[:top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_GPT = sqlite3.connect(\"../Reviews.db\")\n",
    "con_CPM = sqlite3.connect(\"../stories_cn_test.db\")\n",
    "\n",
    "index_GPT = faiss.read_index(\"../IVFPQ_index.bin\")\n",
    "index_CPM = faiss.read_index(\"../stories_cn_ebd.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('Summary: I thought that the Sprout apple are the best...|Text: ...I was wrong! The taste is sweet and sour, and texture just so good (unbelievably good). No regret, proud to find this product. Now, I am buying only this applesauce!\"',\n",
       "  \"Summary: Sweet, Yummy, Super-Crispy|Text: *****<br />These apple chips are sweet, very crispy, and yummy! They don't have the processed or chemically taste that some dried apples have. They also are not soggy at all--I like my apple chips very crispy! They are 100% certified organic, baked with no added sugar (but still are quite sweet), no preservatives or chemicals, no pesticides or herbicides, gluten free, and made from Washington State apples with five apples in every bag. There are 6 servings in every 2.6 ounce bag, with 29 calories in each serving. These are a truly healthy and delicious snack.<br /><br />Highly recommended.<br />*****\",\n",
       "  'Summary: An Apple A Day? Actually 1 1/2 apples|Text: I have a sulfite allergy and was tremendously excited when I discovered these a couple of years ago when visiting my sister in California. What was even more exciting was rediscovering them when Amazon began carrying them. For me, the greatest benefit is that they are sulfite-free, since I have a serious sulfite allergy.<br /><br />The Fuji Apples are gently sweet, and fun to eat. I love carrying them with me, and enjoy them even more as an evening treat. In fact, with these, it would be easy to overdo your daily requirement of fruit! Each package contains only freeze-dried apples, 1 1/2 apples to be exact, and weighs in at 39 calories.<br /><br />Quite honestly, I would personally choose these over chips any day of the week. My sister has several grandchildren who enjoy raiding these from her cupboard, so I can certify that they are also child-approved.<br /><br />I purchased these as part of a variety pack from Amazon, and enjoy all three varieties that came in the package. <a href=\"http://www.amazon.com/gp/product/B001942GAI\">Brothers-ALL-Natural Variety Pack Crisps, Fuji Apple, Asian Pear, Strawberry/Banana, 24-Count  Bags</a> Of the three varieties, this particular one is the one I think kids would enjoy the most because of the apple flavor.',\n",
       "  'Summary: Perfect Apples for baking|Text: These apples packed in water give you the opportunity to add (or not) whatever you want to add as you prepare them for a dish.  Since they are no longer found in the grocery stores, it is a gold mine for me that I can get them from Amazon. An apple pie made with these tastes like you peeled the apples yourself!',\n",
       "  \"Summary: Great Apples|Text: My grandkids and I love these dried apples. I used to buy them at Costco or BJ's but for some reason they no longer carry them. Some stores have a variety pack, but we just like the apples and the pears are good also. I tried other brands, but we like these the best. Wish we could buy them on LI again..\"),\n",
       " (0.9121651, 0.90963167, 0.9070645, 0.89793617, 0.8854335))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss_search(\"I love apples, any recommendation for apple-related products?\", con_GPT, index_GPT, GPT_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('name: 为什么天上会打雷|category: 寓言故事|content: 上帝造好人以后，本来是和人一起住在地上的。那时候，上帝和人混得很熟。人们都很尊敬上帝，天冷的时候，送柴禾给他取暖；缺吃的时候，送食物给他充饥。上帝呢，对大家是一视同仁，不管人间有什么矛盾去找他，他都能公平合理地给调解妥当，让双方心眼口服。因此，那时候，地上的人都生活得十分安宁和欢乐。可是以后上帝老了，人就慢慢对他冷淡起来了。例如旱季到了，天气凉了，人们围着火堆烤火，上帝也凑过来取暖，人们就往外推他。有一个女人甚至拿捣木薯的木杵①捣伤了他的眼睛。上帝生气了，便离开了人间回到了天上。上帝一走，地上可就乱了套了。那些酋长办事不公，正义得不到伸张，邪恶却到处蔓延，人间开始笼罩着痛苦和不幸。一天，上帝打开窗子往地上看，明白了地上发生的一切，他很同情人们的遭遇，便造了一座大桥，一头连着自己的房子，一头连着大地。这样，桥把天和地连接起来，人们如果有事便可以沿着桥去找他了。于是，人间又有了正义，人们又重新获得了安宁与欢乐的生活。这四个人全都怒容满面，三个女人指责她们的丈夫——这个男人抛弃了她们，又爱上了第四个老婆；这男人争辩说没有这回事。上帝听不清楚，让他们一个个地轮流讲，但是他们不听，总是四个喉咙一起响，上帝被吵得头昏脑胀，因此发起火来。上帝发火的声音大极了，不仅天上听得清清楚楚，连地上也听得清清楚楚。人们听到这可怕的声音，吓得赶快躲进屋里去了。发完火，上帝便对四个吵架的人说：“所有的动物都对我唯命是从，只有你们人不遵守我的规矩。你们赶快回去吧，从今以后，人间的事我再也不管了。”从此，人便无法到天上去了，但人间的事上帝仍然了如指掌。为什么天上会打雷一看到人间有什么不顺心的事发生，上帝就发火。一发火，人们就听到了那可怕的声音。这声音就是今天人们常常听到的雷声。\\n\\n\\t①非洲人吃木薯一般有两种方法：一种是像中国人吃红薯一样蒸，另一种是把木薯埋在泥里沤几天，扒出来晒干，再用木杵在臼里捣碎，然后做成糕蒸熟或放油里炸。',\n",
       "  'name: 天为什么这么高|category: 寓言故事|content: 听说从前天并不像现在这么高，天和地是离得很近的。多近呢？人站在地上一伸手就能很容易地把天摸到。上帝一直是住在天上的，他为地上造了人，造了动物，造了植物。他把他造的人当成自己的孩子，为人准备了美味可口的食物，为人制定了切实可行的法律。当时，人们日子过得很不错。\\n\\n\\t可是，捅了好长时间，天一动也不动。寓言。于是，瞎子又想出了另一个办法：在地上点起一堆火，他以为有了火也许能看到东西。大火熊熊燃烧起来，火焰越来越旺，火舌直舔到天上。上帝这时来了，他吃惊地问：“谁点的火？”他万万没有想到自己造出来的人竟敢拿烟斗来捅天，用火来烧天，所以怒气填胸，把手一挥，带着天一步一步地往高处升，一直升到人无论拿什么也够不到的地方。从这以后，天和地就相距得很远很远了。为了惩罚人，上帝让地上总是有瞎子。天为什么这么高',\n",
       "  'name: 太阳和人类_睡前故事|category: 睡前故事|content: 啊——热死了——热死了——该死的太阳!像火一样的太阳。人们纷纷骂，人人骂，都说是太阳惹的祸，是太阳在作怪。其中有个经常说大话的人说：“哼!这太阳烤的我心好烦!如果我会飞，我要飞到太阳边，让它沉下去，再也不让它升起来了!”这话被太阳听见了，它闷闷不乐地说：“冤枉哪!这不是我的错，这是你们人类破坏环境造成的。”可是地球人还是不停地骂太阳，太阳真是伤心极了，它终于起不来了。\\n\\n\\t从此地球没有了光明，伸手不见五指，人类不能做任何事情，植物没有了光合作用也渐渐枯萎了，动物没有了食物都快饿死了。最后地球人终于知道太阳是多么重要。\\n\\n\\t大家摸黑召开紧急会议，讨论该怎么办。最后猫头鹰自告奋勇去请太阳起来工作。太阳和人类_睡前故事“太阳公公请你出来吧!地球离不开您啊!我们己经知道错了请您原谅吧!我们一定会改正错误的。”听了猫头鹰的话，太阳公公气也消了，说：“那好吧。我每天公鸡叫的时候会按时升起的，请地球人放心!”',\n",
       "  'name: 太阳的回答_寓言故事|category: 寓言故事|content: 在古老的时候，有一个老爷爷。他的老伴死了，儿子也死了，媳妇再嫁了；身边只留下一个小孙孙，是老爷爷唯一的亲人。小孙孙名叫伊斯麻，年纪虽小，却是一个精明能干的娃娃。他对阿爷很好，老人晚年的生活，全由小孙娃照应。\\n\\n\\t这一年，老阿爷生病了。伊斯麻端汤捧药，伺候阿爷。从黄昏，到五更；从太阳出，到月亮明。伊斯麻一刻不离阿爷身边，啥时候叫，啥时候答应。\\n\\n\\t老人家多亏了小孙娃体贴照管，挨过了寒冬，病渐渐轻了；春天来了，病快好了，等到夏天，已经能在床上坐一会儿了。伊斯麻见阿爷快恢复健康了，心里说不出的高兴。\\n\\n\\t这一天，天气晴朗，万里无云，一轮火红的太阳照在天空。伊斯麻扶着阿爷，到院子里，让他坐在一块毡子上，暖暖和和晒太阳。\\n\\n\\t伊斯麻走了，老阿爷独自坐在院子里。夏季的太阳大，老阿爷久病体虚，经不起猛然一晒，晒着晒着，只觉眼前乱冒金花花，天旋地转，就昏厥过去了。\\n\\n\\t他哭着把老人抱回屋里去，安放在床上。他想：“太阳啊！你怎么能把我的阿爷晒死呢！——我要找你阿娘说理去！”于是，这勇敢的少年，背了一袋干粮，朝着太阳落山的西方走去。——人们都说，在西方的尽头，便是太阳的家。\\n\\n\\t“呵，人人传说，太阳的阿娘有一副好心肠，你见着她的时候，替我们问一下：人拉木犁耕地，又慢又吃力，用什么办法，能够改变改变？”\\n\\n\\t于是，伊斯麻跨到羊背上。那长毛羊突然腾空一跃，像长上翅膀似地飞了起来。只觉耳边呼呼风响，不知走了几千几万里，来到一个海边的大山下面。长毛羊平稳地落下来，指着一座红墙绿瓦的宫殿说：\\n\\n\\t伊斯麻敲了敲红漆大门，一个白发苍苍的老奶奶走了出来。老奶奶一见伊斯麻，大吃一惊，问道：“少年啊！你怎么到这里来了？”\\n\\n\\t伊斯麻随着太阳的阿娘进到宫殿里。老奶奶拿出许多好吃的东西款待客人，并说：“少年！你放心好了。等我儿子回来，我问个办法，把你阿爷救活就是了。你还有什么事情吗？”\\n\\n\\t伊斯麻又把庄稼人和牧羊人代问的话说了一遍，老阿奶答应一起问一问太阳。正说着，屋子外面忽然红光照耀。老奶奶说：“我儿子回来了。少年！\\n\\n\\t“我很平安，孩子！”老奶奶说。“不过，我觉得你在夏季，照射到人间的热力太强了，那样，将会使庄稼枯焦，给人类带来灾难的。”\\n\\n\\t“那就好。不然，你一个劲地晒，甚至晒死了一个善良的老人——你说说，该用什么办法救活他？”\\n\\n\\t“妈妈！那个老人不过是昏厥了，并没有真死。只消用清泉里的凉水，慢慢在他的额上浸一会儿，他就醒了。”\\n\\n\\t“再说，那牧羊人和他的羊也很苦；本来天气就够热的了，再加上羊毛长得那么长，走路都困难，那多难受啊！”\\n\\n\\t“这很简单，只须用剪刀每年把羊的长毛剪两次，羊轻爽了，剪下的毛还可以捻线、太阳的回答_寓言故事织衣服、洗毡、做毛毯……有很多用处呢。妈妈！您还有什么吩咐吗？”\\n\\n\\t伊斯麻谢过了善良的老奶奶，便仍旧骑上长毛羊，回到了家乡。在路上，他把太阳的话，告诉了牧羊人和庄稼人。他们都很感激，便照着这种办法做：',\n",
       "  'name: 为什么太阳在天上|category: 睡前故事|content: 为什么太阳在天上很多年以前，太阳和水是很好的朋友，他们俩共同生活在地球上。太阳经常来看水，但水却从不回访太阳。\\n\\n\\t终于，太阳忍不住了，就问水为什么从不回访。水回答说，太阳的房子不够大，如果他带着他的家人来，会把太阳挤出自己家的。\\n\\n\\t接着，水又说：“如果你想我去拜访你，你就得建一座非常大的房子。但我警告你，那房子一定要很大，因为我的人很多，要占很多地方。”\\n\\n\\t太阳答应建造一座非常大的房子，然后就回家见妻子月亮。月亮见到丈夫回家，立即笑脸相迎。太阳将他答应水的事情讲给了月亮听。\\n\\n\\t水到达后，他的一位家人大声叫喊太阳，问他水进去后房子是否安全，太阳回答：“是的，叫我的朋友进屋吧。”\\n\\n\\t很快，房子里的水就齐膝了，于是水问太阳房子是否安全，太阳再次说：“是的。”于是，更多的水涌（yǒng）了进来。\\n\\n\\t太阳和月亮都不知道该说什么更好，所以两人齐声说：“是的。”越来越多的水的家人涌进屋内，直至太阳和月亮不得不坐到屋顶上。\\n\\n\\t水再次问太阳他的家人是否可以继续进屋。太阳和月亮的回答仍然是肯定的，于是，越来越多的水的家人涌进屋内。'),\n",
       " (1.0006855, 0.9604471, 0.9579138, 0.95687026, 0.8605685))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss_search(\"太阳为什么从东边升起？\", con_CPM, index_CPM, CPM_embedder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPT_RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
